{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import torch\n",
    "# GPU 模式是否支持\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1.]])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# 5 x 5 零矩阵\n",
    "torch.zeros(5,5)\n",
    "# 5 x 5 元素全为1的矩阵\n",
    "torch.ones(5,5)\n",
    "# 5 x 5 单位矩阵\n",
    "torch.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "shape of I istorch.Size([5, 5])\nreshape in place [all_element:1]torch.Size([25, 1])\n"
    }
   ],
   "source": [
    "I = torch.eye(5)\n",
    "# 获取数组形状\n",
    "print(\"shape of I is \",I.shape)\n",
    "# reshape矩阵\n",
    "print(\"reshape in place [all_element:1] \",I.view(-1,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Tensor"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "torch.tensor([1,3]).shape\n",
    "# converted to python scalars\n",
    "type(torch.tensor(1).item())\n",
    "type(torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "I device is :cpu, B device is: cuda:0\n"
    }
   ],
   "source": [
    "# 将张量移到gpu\n",
    "I = torch.eye(5)\n",
    "\n",
    "B = I.to('cuda')\n",
    "print(f\"I device is :{I.device}, B device is: {B.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " ##  创建 神经网络的方式\n",
    " from torch import nn\n",
    " model = nn.Sequential(  \n",
    "              nn.Linear(10, 10),  \n",
    "              nn.ReLU(),  \n",
    "              nn.Linear(10, 5),  \n",
    "              nn.ReLU(),\n",
    "              nn.Linear(5, 2),  \n",
    "              nn.Softmax(dim=1)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sequential(\n  (0): Linear(in_features=10, out_features=10, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=10, out_features=5, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=5, out_features=2, bias=True)\n  (5): Softmax(dim=1)\n)\ntorch.Size([10, 10])\ntorch.Size([10])\ntorch.Size([5, 10])\ntorch.Size([5])\ntorch.Size([2, 5])\ntorch.Size([2])\n"
    }
   ],
   "source": [
    "print(model)\n",
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('LSUN',\n 'LSUNClass',\n 'ImageFolder',\n 'DatasetFolder',\n 'FakeData',\n 'CocoCaptions',\n 'CocoDetection',\n 'CIFAR10',\n 'CIFAR100',\n 'EMNIST',\n 'FashionMNIST',\n 'QMNIST',\n 'MNIST',\n 'KMNIST',\n 'STL10',\n 'SVHN',\n 'PhotoTour',\n 'SEMEION',\n 'Omniglot',\n 'SBU',\n 'Flickr8k',\n 'Flickr30k',\n 'VOCSegmentation',\n 'VOCDetection',\n 'Cityscapes',\n 'ImageNet',\n 'Caltech101',\n 'Caltech256',\n 'CelebA',\n 'SBDataset',\n 'VisionDataset',\n 'USPS',\n 'Kinetics400',\n 'HMDB51',\n 'UCF101')"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#  常用的示例数据集\n",
    "torchvision.datasets.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(trainloader)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 251.565 248.518125 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\nL 244.365 7.2 \r\nL 26.925 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p1f02218602)\">\r\n    <image height=\"218\" id=\"image400044f5aa\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.64\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"med2892cb24\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#med2892cb24\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#med2892cb24\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#med2892cb24\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#med2892cb24\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#med2892cb24\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#med2892cb24\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m0dee98c959\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0dee98c959\" y=\"11.082857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0dee98c959\" y=\"49.911429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0dee98c959\" y=\"88.74\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0dee98c959\" y=\"127.568571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0dee98c959\" y=\"166.397143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0dee98c959\" y=\"205.225714\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 224.64 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p1f02218602\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "img,label = data.next()\n",
    "print(label[0].item())\n",
    "plt.imshow(img[0][0].numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 784 * 2)\n",
    "        self.fc2 = nn.Linear(784 * 2, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_vector = x.view(-1,784)\n",
    "        fc1_out = F.relu(self.fc1(input_vector))\n",
    "        fc2_out = F.relu(self.fc2(fc1_out))\n",
    "        fc3_out = F.relu(self.fc3(fc2_out))\n",
    "        output = self.fc4(fc3_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim = torch.optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "iter is 200,loss is 0.13608993589878082\niter is 400,loss is 0.12739497423171997\niter is 600,loss is 0.12219467759132385\niter is 800,loss is 0.11658591777086258\niter is 200,loss is 0.06316813826560974\niter is 400,loss is 0.06948794424533844\niter is 600,loss is 0.07205404341220856\niter is 800,loss is 0.07173190265893936\n"
    }
   ],
   "source": [
    "net.cuda()\n",
    "\n",
    "for i in range(2):\n",
    "    run_loss = 0\n",
    "    j = 0\n",
    "    for img,label in trainloader:\n",
    "        img_gpu,label_gpu = img.to('cuda'), label.to('cuda')\n",
    "        output = net(img_gpu)\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(output, label_gpu)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        run_loss += loss\n",
    "        j += 1\n",
    "        if j % 200 == 0:\n",
    "            print(f\"iter is {j},loss is {run_loss/j}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "After Trianing Accuracy of the network on the test images: 98 %\n"
    }
   ],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "net.cpu()\n",
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('After Trianing Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mnist 训练后 准确率提高到了 98%"
   ]
  }
 ]
}